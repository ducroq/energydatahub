name: Collect and Publish Data

on:
  schedule:
    - cron: '0 16 * * *'  # Runs daily at 16:00 UTC (18:00 CET / 20:00 CEST)
  workflow_dispatch:  # Allows manual triggering

jobs:
  collect-and-publish:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Fetch all history for all branches and tags
        token: ${{ secrets.PAT }}  # Personal Access Token (PAT) with repo scope

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Create data directory
      run: mkdir -p data

    - name: Collect data
      env:
        ENCRYPTION_KEY: ${{ secrets.ENCRYPTION_KEY }}
        HMAC_KEY: ${{ secrets.HMAC_KEY }}
        ENTSOE_API_KEY: ${{ secrets.ENTSOE_API_KEY }}
        OPENWEATHER_API_KEY: ${{ secrets.OPENWEATHER_API_KEY }}
        METEO_API_KEY: ${{ secrets.METEO_API_KEY }}
        GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}

      run: python data_fetcher.py

    - name: Sync data to Google Drive (via rclone)
      if: success()
      env:
        RCLONE_CONFIG: ${{ secrets.RCLONE_CONFIG }}
      run: |
        echo "Setting up rclone..."
        # Install rclone
        curl https://rclone.org/install.sh | sudo bash

        # Configure rclone from secret
        if [ -n "$RCLONE_CONFIG" ]; then
          mkdir -p ~/.config/rclone
          echo "$RCLONE_CONFIG" > ~/.config/rclone/rclone.conf

          echo "Copying current endpoint files to Google Drive..."
          rclone copy data/air_history.json data/energy_price_forecast.json data/sun_forecast.json data/weather_forecast.json gdrive:/energyDataHub/current/ --verbose || echo "Warning: Current files sync failed (non-blocking)"

          echo "Archiving timestamped data files to Google Drive..."
          rclone copy data/2*_*.json gdrive:/energyDataHub/archive/ --verbose || echo "Warning: Archive sync failed (non-blocking)"
        else
          echo "Skipping Google Drive sync - RCLONE_CONFIG not configured"
        fi

    - name: Rotate local data (keep last 7 days)
      if: success()
      run: |
        echo "Rotating old data files (keeping last 7 days)..."
        find data -name "2*_*_energy_price_forecast.json" -type f -mtime +7 -delete || true
        find data -name "2*_*_weather_forecast.json" -type f -mtime +7 -delete || true
        find data -name "2*_*_sun_forecast.json" -type f -mtime +7 -delete || true
        find data -name "2*_*_air_history.json" -type f -mtime +7 -delete || true
        echo "Rotation complete"

    - name: Prepare docs folder with only current data
      run: |
        mkdir -p docs
        cp data/air_history.json data/energy_price_forecast.json data/sun_forecast.json data/weather_forecast.json docs/  # Copy only the current forecast files
        cp data/*.log docs/  # Copy log files for debugging

    # - name: List contents of data and docs directories
    #   run: |
    #     echo "Contents of data directory:"
    #     ls -la data/
    #     echo "Contents of docs directory:"
    #     ls -la docs/

    - name: Commit and push if changed
      run: |
        git config --global user.email "action@github.com"
        git config --global user.name "GitHub Action"
        git add -f data/*.json docs/*.json
        git status
        git diff --staged --name-status
        git diff --quiet && git diff --staged --quiet || (git commit -m "Update energy data" && git push)
      env:
        GITHUB_TOKEN: ${{ secrets.PAT }}

    - name: Deploy to GitHub Pages
      uses: peaceiris/actions-gh-pages@v3
      with:
        github_token: ${{ secrets.PAT }}
        publish_dir: ./docs

    # - name: Verify deployment
    #   run: |
    #     echo "Current directory:"
    #     pwd
    #     echo "Contents of current directory:"
    #     ls -la
    #     echo "Contents of docs directory:"
    #     ls -la docs/
